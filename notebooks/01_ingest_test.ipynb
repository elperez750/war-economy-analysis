{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper function to convert number to friendly string",
   "id": "ebe18d9306eafe87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def human_readable(num):\n",
    "    num = float(num)  # make sure it’s numeric\n",
    "    if num >= 1_000_000_000_000:   # Trillions\n",
    "        return f\"{num/1_000_000_000_000:.1f} T\"\n",
    "    elif num >= 1_000_000_000:     # Billions\n",
    "        return f\"{num/1_000_000_000:.1f} B\"\n",
    "    elif num >= 1_000_000:         # Millions\n",
    "        return f\"{num/1_000_000:.1f} M\"\n",
    "    elif num >= 1_000:             # Thousands\n",
    "        return f\"{num/1_000:.0f} K\"\n",
    "    else:\n",
    "        return str(num)\n"
   ],
   "id": "b8eaa39f268afcfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def write_ndjson_local(country_gw: int, year: int, page: int, rows: list, base_dir=\"data\"):\n",
    "    \"\"\"\n",
    "    Write a page of UCDP events to an NDJSON file under data/raw/.\n",
    "\n",
    "    Structure:\n",
    "      data/\n",
    "        raw/\n",
    "          country=090/\n",
    "            year=1989/\n",
    "              page=00001.ndjson\n",
    "    \"\"\"\n",
    "    base = Path(base_dir) / \"raw\" / f\"country={country_gw:03d}\" / f\"year={year}\"\n",
    "    base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    path = base / f\"page={page:05d}.ndjson\"\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "    return str(path)"
   ],
   "id": "eb5a9c654d8779bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "SqlCellData": {
     "variableName$1": "df_sql1"
    }
   },
   "cell_type": "code",
   "source": "%%sql\n",
   "id": "38c2603ca2ba6a11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Getting GDP information from WorldBank",
   "id": "337f96406a5683f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "BASE = \"https://api.worldbank.org/v2/country/{country}/indicator/{indicator}\"\n",
    "\n",
    "\n",
    "COUNTRIES = [\"USA\", \"MEX\", \"GBR\"]\n",
    "INDICATORS = {\n",
    "    \"NY.GDP.MKTP.CD\": \"gdp_usd\",\n",
    "    \"SP.POP.TOTL\": \"population\",\n",
    "    \"MS.MIL.XPND.GD.ZS\": \"mil_exp_pct_gdp\",\n",
    "    \"MS.MIL.XPND.CD\": \"mil_exp_usd\",\n",
    "}\n",
    "\n",
    "START, END = 2012, 2023\n",
    "\n",
    "def fetch_indicator(country, start, end):\n",
    "    merged = None\n",
    "    for code, colname in INDICATORS.items():\n",
    "        url = BASE.format(country=country, indicator=code)\n",
    "        params = {\"format\": \"json\", \"date\": f\"{start}:{end}\", \"per_page\": 20000}\n",
    "        r = requests.get(url, params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "        rows = payload[1] if isinstance(payload, list) and len(payload) > 1 else []\n",
    "\n",
    "        df = pd.DataFrame([\n",
    "            {\n",
    "                \"country\": row[\"country\"][\"value\"],\n",
    "                \"iso3\": row[\"countryiso3code\"],\n",
    "                \"year\": int(row[\"date\"]),\n",
    "                colname: row[\"value\"],\n",
    "            }\n",
    "            for row in rows if row.get(\"value\") is not None\n",
    "        ])\n",
    "\n",
    "        # merge indicator onto main DataFrame\n",
    "        if merged is None:\n",
    "            merged = df\n",
    "        else:\n",
    "            merged = pd.merge(merged, df, on=[\"country\", \"iso3\", \"year\"], how=\"outer\")\n",
    "\n",
    "    merged['gdp_string'] = merged['gdp_usd'].apply(human_readable)\n",
    "    merged['population_string'] = merged['population'].apply(human_readable)\n",
    "    return merged.sort_values(\"year\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "frames = [fetch_indicator(c, START, END) for c in COUNTRIES]\n",
    "df = pd.concat(frames).sort_values([\"year\"]).reset_index(drop=True)\n",
    "\n",
    "df.head(50)\n",
    "# df.to_csv(\"gdp_countries.csv\", index=False)\n"
   ],
   "id": "4db23fab4fd36e0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Must have columns include\n",
    "from pathlib import Path\n",
    "import time, json\n",
    "'''\n",
    "id\n",
    "country_id\n",
    "year\n",
    "country\n",
    "ged_events (This will basically count the number of incidents in a year)\n",
    "ged_events_fatal (This will basically the events that ended up being fatal)\n",
    "ged_deaths_best (This will show the best estimate on how many people were killed\n",
    "ged_deaths_civilians (This will be the sum of all of the civilian deaths)\n",
    "ged_deaths_low (This will be a sum of all of the low death estimates)\n",
    "ged_deaths_high (This will be a sum of all of the high death estimates)\n",
    "ged_dyads (This will be a count of all the dyad_new_id that we have)\n",
    "ged_state_events (This will show the events that have 1)\n",
    "ged_nonstate_events (This will show the events that have 2)\n",
    "ged_onesided_events (This will show the events that have 3)\n",
    "'''\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import time, json\n",
    "\n",
    "def save_raw(df):\n",
    "    \"\"\"Save the raw API rows to JSONL (raw layer).\"\"\"\n",
    "    raw_base = Path(\"data/raw/gedevents\")\n",
    "    raw_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ts = int(time.time())\n",
    "    raw_path = raw_base / f\"all_countries_part-{ts}.jsonl\"\n",
    "\n",
    "    with open(raw_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(json.dumps(row.dropna().to_dict(), ensure_ascii=False, default=str) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Wrote RAW JSONL to {raw_path}\")\n",
    "\n",
    "\n",
    "def save_processed(agg):\n",
    "    \"\"\"Save the aggregated country-year data to partitioned Parquet (processed layer).\"\"\"\n",
    "    processed_base = Path(\"data/processed/gedevents\")\n",
    "    processed_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ts = int(time.time())\n",
    "    rows_written = 0\n",
    "\n",
    "    for (yr, cid), part in agg.groupby([\"year\", \"country_id\"], dropna=False):\n",
    "        out_dir = processed_base / f\"year={int(yr)}\" / f\"country_id={int(cid)}\"\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_dir / f\"part-{ts}.parquet\"\n",
    "        part.to_parquet(out_path, index=False, engine='fastparquet')\n",
    "        rows_written += len(part)\n",
    "\n",
    "    print(f\"✅ Wrote {rows_written} rows to Parquet under {processed_base}/\")\n",
    "\n"
   ],
   "id": "a20e47148efd2bac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Getting information from UCDP\n",
   "id": "a6eeb019c262d4dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests, time, json\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://ucdpapi.pcr.uu.se/api/gedevents/25.1\"\n",
    "\n",
    "GW_CODES = [645, 700, 775, 540, 666]\n",
    "\n",
    "all_events = []\n",
    "\n",
    "for country in GW_CODES:\n",
    "    print(f\"\\n=== Starting retrieval for country code: {country} ===\")\n",
    "\n",
    "    url = BASE_URL\n",
    "\n",
    "    params = {\n",
    "        \"Country\": country,\n",
    "        \"StartDate\": \"1989-01-01\",\n",
    "        \"EndDate\": \"1991-12-31\",\n",
    "        \"pagesize\": 1000\n",
    "    }\n",
    "\n",
    "\n",
    "    while True:\n",
    "        r = requests.get(url, params=params if url == BASE_URL else None, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        payload = r.json()\n",
    "\n",
    "        events = payload.get(\"Result\", [])\n",
    "        all_events.extend(events)\n",
    "\n",
    "        next_url = payload.get(\"NextPageUrl\")\n",
    "        if not next_url:\n",
    "            break\n",
    "        url, params = next_url, None  # NextPageUrl already includes query params\n",
    "        time.sleep(0.2)               # gentle pacing\n",
    "\n",
    "    print(\"\\n--- Retrieval Complete ---\")\n",
    "    print(f\"Total events retrieved: {len(all_events)}\")\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(all_events)\n",
    "\n",
    "# Parse dates & cast numerics safely\n",
    "df[\"date_start\"] = pd.to_datetime(df.get(\"date_start\"), errors=\"coerce\")\n",
    "for col in [\"best\", \"low\", \"high\", \"deaths_civilians\"]:\n",
    "    df[col] = pd.to_numeric(df.get(col), errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Aggregate to Country–Year\n",
    "agg = (\n",
    "    df.groupby([\"country_id\", \"country\", \"year\"], dropna=False)\n",
    "      .agg(\n",
    "          ged_events          = (\"id\", \"count\"),\n",
    "          ged_events_fatal    = (\"best\", lambda x: (x > 0).sum()),\n",
    "          ged_deaths_best     = (\"best\", \"sum\"),\n",
    "          ged_deaths_low      = (\"low\", \"sum\"),\n",
    "          ged_deaths_high     = (\"high\", \"sum\"),\n",
    "          ged_deaths_civilians= (\"deaths_civilians\", \"sum\"),\n",
    "          ged_dyads           = (\"dyad_new_id\", \"nunique\"),\n",
    "          ged_state_events    = (\"type_of_violence\", lambda x: (x == 1).sum()),\n",
    "          ged_nonstate_events = (\"type_of_violence\", lambda x: (x == 2).sum()),\n",
    "          ged_onesided_events = (\"type_of_violence\", lambda x: (x == 3).sum()),\n",
    "      )\n",
    "      .reset_index()\n",
    "      .sort_values([\"country_id\", \"year\"])\n",
    ")\n",
    "\n",
    "save_raw(df)\n",
    "save_processed(agg)\n",
    "\n",
    "# # Chronological preview of raw events\n",
    "# df_sorted = df.sort_values([\"year\", \"date_start\", \"id\"])\n",
    "# print(\"\\nFirst 5 events chronologically:\")\n",
    "# print(df_sorted[[\"id\",\"year\",\"country\",\"date_start\",\"best\",\"deaths_civilians\"]].head(5))\n",
    "#\n",
    "# print(\"\\nLast 5 events chronologically:\")\n",
    "# print(df_sorted[[\"id\",\"year\",\"country\",\"date_start\",\"best\",\"deaths_civilians\"]].tail(5))\n"
   ],
   "id": "cd5457b17aef32ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21cc4f85e03e5b7d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
